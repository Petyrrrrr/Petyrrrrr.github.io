---
layout: archive
title: "Experiences"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

You can find my CV [here](../assets/Tianze_CV (5).pdf) (short) or [here](../assets/Tianze_J_CV.pdf) (long).

&nbsp;

Education
======
* B.S., Massachusetts Institute of Technology, 2020-2024
  * Double Major in Mathematics (Course 18) and Computer Science (Course 6-3).
  * GPA: 5.0/5.0. See a selected coursework in my CV.


&nbsp;

Honors
======
* William Lowell Putnam Math Competition N1 (Top 15 Overall), 2021
* International Math Olympiad (IMO) Silver Medal (Team USA), 2020
* USA Math Olympiad (USAMO) winner, 5th place overall, 2020
* Asian-Pacific Math Olympiad, 3rd place worldwide, 2020
* Chinese IMO Team Candidate Top 15, 2018

&nbsp;

Recent Publications
======
* [Optimal Prediction Risk via Compression]()
  * Co-authored with Yanjun Han and Yihong Wu.
  * Under preparation/submitted.
* [Density Estimation Using the Perceptron](https://bit.ly/halfspaces)
  * Co-authored with Patrik Gerber, Yury Polyanskiy, and Rui Sun.
  * Under preparation/submitted.
* [Kernel-based Tests for Likelihood-Free Hypothesis Testing](https://openreview.net/forum?id=paTESG8iSE)
  * Co-authored with Patrik Gerber, Yury Polyanskiy, and Rui Sun.
  * Accepted for Posters at the 2023 NeurIPS (New Orleans, USA).
* [Detection-Recovery and Detection-Refutation Gaps via Reductions from Planted Clique](https://proceedings.mlr.press/v195/bresler23a.html)
  * Co-authored with Guy Bresler.
  * Accepted at the 2023 COLT (Bangalore, India).

&nbsp;
  
Talks
======
* Sampling via diffusion and stochastic localization (Nov., 2023)
  * Presented at group meeting of Prof. Guy Bresler, MIT LIDS.
  * TLDR: combining empirically-motivated diffusion techniques with algorithmic guarantees gives efficient sampling algorithms on highly-theoretical statistical models.
* Computational lower bounds via average-case reductions (Oct., 2023)
  * Presented at group meeting of Prof. Sitan Chen, Harvard SEAS.
  * TLDR: using average-case reductions from the Planted Clique, we provide strong evidence of hardness for a variety of signal-plus-noise problems.
* Slicing with random half-spaces (Apr., 2023)
  * Presented at group meetings of Prof. Mert Pilanci, Stanford EE, and Prof. Guy Bresler, MIT LIDS.
  * TLDR: (projection mass on) a random halfspace encodes a significant amount of information for smooth distributions and GMMs, motivating some provable GAN designs. 
* Likelihood-Free Inference with kernels (Dec., 2022)
  * Presented at group meeting of Prof. Yury Polyanskiy, MIT LIDS.
  * TLDR: kernel methods on likelihood-free testing gives sample complexity bounds with minimal assumpstions and recover several past results on smooth and discrete distributions.

&nbsp;

Work experience
======
* Summer 2021: Quantitative Research Intern, TongDeng Fund (Shanghai China)
  * Worked on position optimizing algorithm based on T+1 stock market constraint.

&nbsp;

Teaching
======
* Teaching Assistant of 6.3700 (Introduction to Probability), 2023 Spring
  * Created a set of Jupyter Demos for course concepts.
  * Held Office Hours, proofread course materials.
  * TA Evaluation: 6.5/7.0
* Teaching Assistant of 6.7810 (Algorithms for Inference), 2022 Fall
  * Graded Homeworks, proofread course materials.
  * TA Evaluation: 7.0/7.0
